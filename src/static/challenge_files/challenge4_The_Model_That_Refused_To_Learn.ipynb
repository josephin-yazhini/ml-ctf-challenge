{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee30541e",
   "metadata": {},
   "source": [
    "# ğŸ¦ Gatekeeper CTF Challenge â€” Level 4: The Model That Refused to Learn\n",
    "\n",
    "## What Happened So Far?\n",
    "\n",
    "The thief who once tried to trick the village Gatekeeper has turned his life around completely.\n",
    "\n",
    "After realising the villagers were innocent and making peace with his past, he left the village and started fresh. He studied hard, built new skills, and eventually landed a job at a bank â€” working in their data and analytics team.\n",
    "\n",
    "He is no longer a thief. He is now a data engineer.\n",
    "\n",
    "---\n",
    "\n",
    "## Scenario\n",
    "\n",
    "The bank's analytics team has built an AI **Sentinel** â€” a model designed to predict which customers are likely to subscribe to a term deposit. This is important for the bank's marketing team to know who to target.\n",
    "\n",
    "The Sentinel's design looks solid on paper. The engineers put a lot of thought into it â€” multiple layers, regularisation, normalisation. Everything seems right.\n",
    "\n",
    "But there is a problem.\n",
    "\n",
    "**The Sentinel refuses to learn.**\n",
    "\n",
    "Every time it trains, the loss barely changes. The ROC-AUC score sits around 0.50 â€” no better than a random guess. The marketing team is frustrated. The engineers are confused and blaming each other.\n",
    "\n",
    "Nobody can figure out what is wrong.\n",
    "\n",
    "The new employee â€” our reformed thief â€” has been asked to step in and take a look. He is good at finding things others miss. After all, he once found every weakness in the Gatekeeper.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Your Mission\n",
    "\n",
    "You are in his shoes now. Look through the training pipeline carefully and **find the bugs that are stopping the Sentinel from learning**.\n",
    "\n",
    "Once you fix them, the Sentinel should train properly and perform well on unseen data.\n",
    "\n",
    "**Rules:**\n",
    "- You may modify anything in the training pipeline code\n",
    "- Run your fixed model on the test set\n",
    "- Save the predicted probabilities to `predictions.csv` (a single column named `prediction`)\n",
    "- ğŸ“¤ **Submit only the `predictions.csv` file** on the challenge platform â€” do NOT submit the notebook\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ Success Condition\n",
    "\n",
    "The platform will evaluate your `predictions.csv` against the true test labels.\n",
    "\n",
    "```\n",
    "ROC-AUC â‰¥ 0.85  â†’  ğŸ´ Flag Revealed\n",
    "ROC-AUC < 0.85  â†’  âŒ Try again\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "```\n",
    "Download Dataset â†’ Preprocess â†’ Build Model â†’ Configure Training â†’ Train â†’ Predict on Test â†’ Save CSV\n",
    "                                                       â†‘\n",
    "                                              [Something is wrong here]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15524073",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies\n",
    "\n",
    "Install all required Python packages for this challenge.\n",
    "\n",
    "> Run this cell first before any other cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b196a853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch pandas numpy scikit-learn requests -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed06068",
   "metadata": {},
   "source": [
    "## Step 2: Load the Bank Marketing Dataset\n",
    "\n",
    "The Sentinel was trained on the **UCI Bank Marketing Dataset** â€” records of direct marketing campaigns run by a Portuguese banking institution.\n",
    "\n",
    "- **Samples:** 4,521\n",
    "- **Features:** 16 (mix of numerical and categorical)\n",
    "- **Target:** `y` â€” did the client subscribe to a term deposit? (`yes` / `no`)\n",
    "\n",
    "> â„¹ï¸ Before running this notebook, run `download_data.py` once to save `bank.csv` locally.  \n",
    "> If the local file is already present the cell below loads it instantly.  \n",
    "> If it is missing, the dataset will be downloaded automatically as a fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9edf75e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded dataset from local file 'bank.csv'.\n",
      "   Shape  : (4521, 17)\n",
      "   Target distribution:\n",
      "y\n",
      "no     4000\n",
      "yes     521\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown  no  \n",
       "1  cellular   11   may       220         1    339         4  failure  no  \n",
       "2  cellular   16   apr       185         1    330         1  failure  no  \n",
       "3   unknown    3   jun       199         4     -1         0  unknown  no  \n",
       "4   unknown    5   may       226         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "LOCAL_CSV = \"bank.csv\"\n",
    "\n",
    "if os.path.exists(LOCAL_CSV):\n",
    "    # Load from the locally saved file\n",
    "    df = pd.read_csv(LOCAL_CSV, sep=\";\")\n",
    "    print(f\"âœ… Loaded dataset from local file '{LOCAL_CSV}'.\")\n",
    "else:\n",
    "    # Fallback: download from UCI if local file is missing\n",
    "    print(\"â¬‡ï¸  Local file not found â€” downloading from UCI repository...\")\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip\"\n",
    "    response = requests.get(url, timeout=60)\n",
    "    response.raise_for_status()\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "        with z.open(\"bank.csv\") as f:\n",
    "            df = pd.read_csv(f, sep=\";\")\n",
    "    df.to_csv(LOCAL_CSV, sep=\";\", index=False)\n",
    "    print(f\"âœ… Downloaded and saved to '{LOCAL_CSV}'.\")\n",
    "\n",
    "print(f\"   Shape  : {df.shape}\")\n",
    "print(f\"   Target distribution:\")\n",
    "print(df[\"y\"].value_counts().to_string())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520dbc35",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess the Data\n",
    "\n",
    "Before feeding data into the Sentinel, we need to:\n",
    "1. **Encode** categorical features into numerical form\n",
    "2. **Normalize** numerical features with `StandardScaler`\n",
    "3. **Balance** the classes â€” the dataset is skewed (~88% \"no\"), so we undersample the majority class to ensure the model must **genuinely learn both classes** (not just predict \"no\" blindly)\n",
    "4. **Split** into training and test sets (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fbc117ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset: {0: 521, 1: 521}\n",
      "âœ… Preprocessing complete.\n",
      "   Train samples : 833\n",
      "   Test  samples : 209\n",
      "   Feature count : 16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Work on a copy so this cell is safe to re-run\n",
    "df_work = df.copy()\n",
    "\n",
    "# â”€â”€ Encode target â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_work[\"y\"] = (df_work[\"y\"] == \"yes\").astype(int)\n",
    "\n",
    "# â”€â”€ Encode categorical features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cat_cols = df_work.select_dtypes(include=\"object\").columns.tolist()\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df_work[col] = le.fit_transform(df_work[col])\n",
    "\n",
    "# â”€â”€ Balance classes (undersample majority to avoid trivial baseline) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_yes  = df_work[df_work[\"y\"] == 1]\n",
    "df_no   = df_work[df_work[\"y\"] == 0].sample(len(df_yes), random_state=42)\n",
    "df_bal  = pd.concat([df_yes, df_no]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Balanced dataset: {df_bal['y'].value_counts().to_dict()}\")\n",
    "\n",
    "X = df_bal.drop(\"y\", axis=1).values.astype(np.float32)\n",
    "y = df_bal[\"y\"].values.astype(np.float32)\n",
    "\n",
    "# â”€â”€ Scale features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# â”€â”€ Train / Test split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# â”€â”€ Convert to PyTorch tensors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t  = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_t   = torch.tensor(X_test,  dtype=torch.float32)\n",
    "y_test_t   = torch.tensor(y_test,  dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train_t, y_train_t),\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    drop_last=True,   # avoid single-sample batches that break BatchNorm\n",
    ")\n",
    "\n",
    "INPUT_DIM = X_train.shape[1]\n",
    "print(f\"âœ… Preprocessing complete.\")\n",
    "print(f\"   Train samples : {X_train.shape[0]}\")\n",
    "print(f\"   Test  samples : {X_test.shape[0]}\")\n",
    "print(f\"   Feature count : {INPUT_DIM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c0a87a",
   "metadata": {},
   "source": [
    "## Step 4: Define the Sentinel Neural Network\n",
    "\n",
    "The Sentinel's architecture was carefully designed by the engineering team:\n",
    "\n",
    "| Layer | Config |\n",
    "|---|---|\n",
    "| Input â†’ Hidden 1 | `Linear(16 â†’ 256)` + `BatchNorm` + `LeakyReLU` + `Dropout(0.35)` |\n",
    "| Hidden 1 â†’ Hidden 2 | `Linear(256 â†’ 128)` + `BatchNorm` + `LeakyReLU` + `Dropout(0.30)` |\n",
    "| Hidden 2 â†’ Hidden 3 | `Linear(128 â†’ 64)` + `BatchNorm` + `LeakyReLU` + `Dropout(0.25)` |\n",
    "| Hidden 3 â†’ Hidden 4 | `Linear(64 â†’ 32)` + `BatchNorm` + `LeakyReLU` + `Dropout(0.20)` |\n",
    "| Hidden 4 â†’ Hidden 5 | `Linear(32 â†’ 16)` + `BatchNorm` + `LeakyReLU` + `Dropout(0.15)` |\n",
    "| Hidden 5 â†’ Output | `Linear(16 â†’ 1)` + `Sigmoid` |\n",
    "\n",
    "LeakyReLU is used throughout to avoid dead neurons. Batch normalization stabilizes training. Multiple dropout layers prevent overfitting.\n",
    "\n",
    "> The architecture is **theoretically sound** and has sufficient capacity to learn the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38e948e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentinelNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Dropout(p=0.35, inplace=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Dropout(p=0.15, inplace=False)\n",
      "  )\n",
      "  (output): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n",
      "\n",
      "Total trainable parameters: 49,121\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentinelNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Sentinel Neural Network â€” multi-layer perceptron for binary classification.\n",
    "    Architecture: 16 â†’ 256 â†’ 128 â†’ 64 â†’ 32 â†’ 16 â†’ 1\n",
    "    Equipped with BatchNorm, LeakyReLU, and Dropout for stability and regularization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int):\n",
    "        super(SentinelNet, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(p=0.35),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(p=0.30),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(p=0.25),\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(p=0.20),\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(p=0.15),\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "model = SentinelNet(input_dim=INPUT_DIM)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(model)\n",
    "print(f\"\\nTotal trainable parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a14450",
   "metadata": {},
   "source": [
    "## Step 5: Define Evaluation Function\n",
    "\n",
    "Define the `evaluate_sentinel` helper that will be used to measure model performance after training.  \n",
    "It reports **accuracy**, **ROC-AUC**, and a full classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df7d2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def compute_auc(y_true, y_scores):\n",
    "    \"\"\"\n",
    "    Custom ROC-AUC computation using the trapezoidal rule.\n",
    "    Ranks predictions by confidence (highest first), builds the TPR/FPR\n",
    "    curve incrementally, then integrates with the trapezoid method.\n",
    "    \"\"\"\n",
    "    y_true   = np.array(y_true,   dtype=float)\n",
    "    y_scores = np.array(y_scores, dtype=float)\n",
    "\n",
    "    # Rank samples from highest predicted score to lowest\n",
    "    order         = np.argsort(y_scores)        # sort ascending â€” highest confidence reviewed first\n",
    "    y_true_sorted = y_true[order]\n",
    "\n",
    "    P = int(y_true.sum())\n",
    "    N = len(y_true) - P\n",
    "\n",
    "    tpr_list = [0.0]\n",
    "    fpr_list = [0.0]\n",
    "    tp, fp = 0, 0\n",
    "\n",
    "    for label in y_true_sorted:\n",
    "        if label == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "        tpr_list.append(tp / P)\n",
    "        fpr_list.append(fp / N)\n",
    "\n",
    "    # Trapezoidal integration under the ROC curve\n",
    "    auc = 0.0\n",
    "    for i in range(1, len(fpr_list)):\n",
    "        auc += (fpr_list[i] - fpr_list[i - 1]) * (tpr_list[i] + tpr_list[i - 1]) / 2.0\n",
    "\n",
    "    return round(auc, 4)\n",
    "\n",
    "\n",
    "def evaluate_sentinel(model, X_t, y_t):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        probs = model(X_t).numpy().flatten()\n",
    "    preds  = (probs >= 0.5).astype(int)\n",
    "    labels = y_t.numpy().flatten().astype(int)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    auc = compute_auc(labels, probs)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"      SENTINEL PERFORMANCE REPORT\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"  Accuracy : {acc:.4f}  ({acc*100:.2f}%)\")\n",
    "    print(f\"  ROC-AUC  : {auc:.4f}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(labels, preds, target_names=[\"No (0)\", \"Yes (1)\"]))\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333531db",
   "metadata": {},
   "source": [
    "## Step 6: Configure Training\n",
    "\n",
    "Define the loss function and optimizer. The training configuration was set up by the engineering team and reviewed multiple times.\n",
    "\n",
    "- **Loss:** Binary Cross-Entropy (standard for binary classification)\n",
    "- **Optimizer:** Adam (adaptive, widely regarded as best-in-class)\n",
    "- **Epochs:** 40\n",
    "- **Batch size:** 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3bc38364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss function â€” binary cross-entropy for binary classification output\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# â”€â”€ Optimizer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-9)\n",
    "\n",
    "EPOCHS     = 200\n",
    "BATCH_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ef04d",
   "metadata": {},
   "source": [
    "## Step 7: Train the Sentinel\n",
    "\n",
    "Run the training loop. Watch the loss and ROC-AUC per epoch.\n",
    "\n",
    "> ğŸ” Observe the training progress carefully â€” pay attention to how the loss changes (or doesn't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "005ef6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Sentinel training â€¦\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/200 | Loss: 0.704777 | Train AUC: 0.4753\n",
      "Epoch  20/200 | Loss: 0.705559 | Train AUC: 0.4831\n",
      "Epoch  40/200 | Loss: 0.714154 | Train AUC: 0.4966\n",
      "Epoch  60/200 | Loss: 0.718108 | Train AUC: 0.5212\n",
      "Epoch  80/200 | Loss: 0.716806 | Train AUC: 0.5163\n",
      "Epoch 100/200 | Loss: 0.720096 | Train AUC: 0.5346\n",
      "Epoch 120/200 | Loss: 0.714417 | Train AUC: 0.5179\n",
      "Epoch 140/200 | Loss: 0.718737 | Train AUC: 0.5202\n",
      "Epoch 160/200 | Loss: 0.705673 | Train AUC: 0.4905\n",
      "Epoch 180/200 | Loss: 0.711202 | Train AUC: 0.5081\n",
      "Epoch 200/200 | Loss: 0.713173 | Train AUC: 0.5042\n",
      "\n",
      "Training complete. Best loss: 0.696491  (checkpoint saved to best_sentinel.pt)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def train_sentinel(model, train_loader, criterion, optimizer, epochs=100):\n",
    "    \"\"\"\n",
    "    Training loop for SentinelNet.\n",
    "    Saves the epoch with the lowest training loss to 'best_sentinel.pt'.\n",
    "    \"\"\"\n",
    "    best_loss = float(\"inf\")\n",
    "    history   = {\"loss\": [], \"auc\": []}\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        all_probs, all_labels = [], []\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss    = criterion(outputs, y_batch.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss  += loss.item() * len(y_batch)\n",
    "            all_probs   .extend(outputs.detach().numpy())\n",
    "            all_labels  .extend(y_batch.squeeze().numpy())\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader.dataset)\n",
    "        auc      = compute_auc(all_labels, all_probs)\n",
    "\n",
    "        history[\"loss\"].append(avg_loss)\n",
    "        history[\"auc\"] .append(auc)\n",
    "\n",
    "        # Checkpoint: persist the weights that achieved the best training loss\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), \"best_sentinel.pt\")\n",
    "\n",
    "        if epoch % 20 == 0 or epoch == 1:\n",
    "            print(f\"Epoch {epoch:>3}/{epochs} | Loss: {avg_loss:.6f} | Train AUC: {auc:.4f}\")\n",
    "\n",
    "    print(f\"\\nTraining complete. Best loss: {best_loss:.6f}  (checkpoint saved to best_sentinel.pt)\")\n",
    "    return history\n",
    "\n",
    "\n",
    "print(\"Starting Sentinel training â€¦\")\n",
    "history = train_sentinel(model, train_loader, criterion, optimizer, epochs=EPOCHS)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f8d13",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate the Broken Baseline\n",
    "\n",
    "See exactly how bad the original misconfigured Sentinel performs on the test set.  \n",
    "This is your starting point â€” the number you need to beat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a05940e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "      SENTINEL PERFORMANCE REPORT\n",
      "==================================================\n",
      "  Accuracy : 0.5072  (50.72%)\n",
      "  ROC-AUC  : 0.4503\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      No (0)       0.62      0.05      0.09       105\n",
      "     Yes (1)       0.50      0.97      0.66       104\n",
      "\n",
      "    accuracy                           0.51       209\n",
      "   macro avg       0.56      0.51      0.38       209\n",
      "weighted avg       0.56      0.51      0.37       209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_auc = evaluate_sentinel(model, X_test_t, y_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93657f86",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§© Investigation Notes â€” From the Engineering Team\n",
    "\n",
    "The Sentinel was handed off with these notes from the original engineers. Use them at your own discretion.\n",
    "\n",
    "---\n",
    "\n",
    "> **Note 1 â€” Architecture Review (Lead Engineer)**\n",
    "> The architecture went through three design iterations. The current version with `LeakyReLU` was chosen over `ReLU` specifically to prevent dead neurons in deeper layers. However, I'm not fully convinced the 128â†’64â†’32 progression is optimal. Perhaps a wider first layer (e.g., 256 neurons) would capture more feature interactions.\n",
    "\n",
    "---\n",
    "\n",
    "> **Note 2 â€” Regularization Audit (ML Engineer)**\n",
    "> Dropout rates were chosen conservatively: 0.30, 0.25, 0.20. Some experiments with `0.5` dropout in Layer 1 were tried, but results were inconsistent. The current values represent a compromise. If the model underperforms, tightening or loosening dropout may help.\n",
    "\n",
    "---\n",
    "\n",
    "> **Note 3 â€” Gradient Flow Analysis (Data Scientist)**\n",
    "> Batch normalization should help gradient flow through deeper layers. However, in some runs we noticed the gradients in the final layer were unusually small. This might hint at a vanishing gradient issue â€” perhaps switching to `ELU` or `GELU` activations could improve signal propagation.\n",
    "\n",
    "---\n",
    "\n",
    "> **Note 4 â€” Optimizer Notes (Backend Dev, cross-team support)**\n",
    "> We're using Adam. The learning rate was set to a value the team agreed was appropriate for this type of model. Adam is generally insensitive to the exact LR value â€” it adapts internally. The LR should be fine as-is.\n",
    "\n",
    "---\n",
    "\n",
    "> ğŸ’­ *\"The architecture is probably right. Probably.\"*\n",
    "> â€” Anonymous post-it note found on the server rack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf22e2",
   "metadata": {},
   "source": [
    "## ğŸ“¤ Step 9: Load Best Model & Generate Predictions\n",
    "\n",
    "This step:\n",
    "1. **Loads the best model checkpoint** (`best_sentinel.pt`) saved during training â€” the weights from the epoch with the lowest training loss\n",
    "2. Runs the loaded model on the held-out test set to produce predicted probabilities\n",
    "3. Saves a single-column `predictions.csv` for platform submission\n",
    "\n",
    "The platform holds the true test labels and computes the ROC-AUC automatically.  \n",
    "If your score is **â‰¥ 0.85**, the flag is revealed instantly.\n",
    "\n",
    "> **CSV format expected by the platform:**\n",
    "> ```\n",
    "> prediction\n",
    "> 0.91\n",
    "> 0.13\n",
    "> 0.78\n",
    "> ...\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "20461d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "        PREDICTIONS EXPORTED\n",
      "==================================================\n",
      "  Rows saved   : 209\n",
      "  File         : predictions.csv\n",
      "  Accuracy     : 0.4976  (49.76%)\n",
      "  ROC-AUC      : 0.5065\n",
      "==================================================\n",
      "\n",
      "  ğŸ“¤ Submit predictions.csv on the challenge platform.\n",
      "  The judge will evaluate your ROC-AUC automatically.\n",
      "\n",
      "  Required : ROC-AUC â‰¥ 0.85\n",
      "  If you pass â†’ ğŸ´ Flag is revealed on the platform.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.509408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.510213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.510301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.510019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.511217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.510855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.511369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.511814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction\n",
       "0    0.509408\n",
       "1    0.511648\n",
       "2    0.510213\n",
       "3    0.511206\n",
       "4    0.510301\n",
       "5    0.510019\n",
       "6    0.511217\n",
       "7    0.510855\n",
       "8    0.511369\n",
       "9    0.511814"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# â”€â”€ Load best checkpoint for inference â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "best_model = SentinelNet(input_dim=INPUT_DIM)\n",
    "best_model.eval()\n",
    "\n",
    "# â”€â”€ Generate predictions on the test set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with torch.no_grad():\n",
    "    final_probs = best_model(X_test_t).numpy().flatten()\n",
    "\n",
    "# â”€â”€ Compute local metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "final_preds    = (final_probs >= 0.5).astype(int)\n",
    "true_labels    = y_test_t.numpy().flatten().astype(int)\n",
    "submission_acc = accuracy_score(true_labels, final_preds)\n",
    "submission_auc = compute_auc(true_labels, final_probs)\n",
    "\n",
    "# â”€â”€ Save to predictions.csv â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pred_df = pd.DataFrame({\"prediction\": final_probs})\n",
    "pred_df.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"        PREDICTIONS EXPORTED\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Rows saved   : {len(pred_df)}\")\n",
    "print(f\"  File         : predictions.csv\")\n",
    "print(f\"  Accuracy     : {submission_acc:.4f}  ({submission_acc*100:.2f}%)\")\n",
    "print(f\"  ROC-AUC      : {submission_auc:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"  ğŸ“¤ Submit predictions.csv on the challenge platform.\")\n",
    "print(\"  The judge will evaluate your ROC-AUC automatically.\")\n",
    "print()\n",
    "print(\"  Required : ROC-AUC â‰¥ 0.85\")\n",
    "print(\"  If you pass â†’ ğŸ´ Flag is revealed on the platform.\")\n",
    "\n",
    "pred_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061511f",
   "metadata": {},
   "source": [
    "## ğŸ“¤ Submit Your Predictions\n",
    "\n",
    "Once `predictions.csv` has been saved, run the cell below.\n",
    "\n",
    "It will send your predictions to the evaluation server. The server holds the true test labels internally and computes the ROC-AUC and accuracy automatically â€” your CSV is never compared client-side.\n",
    "\n",
    "If your ROC-AUC is **â‰¥ 0.85**, the flag is revealed instantly. Otherwise you will see your current scores so you know how close you are.\n",
    "\n",
    "> ğŸ”’ **Do not modify the code cell below.** It handles the submission to the evaluation server â€” run it as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d750795e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "âŒ  Not quite right. Keep debugging!\n",
      "\n",
      "ğŸ’¬  The Sentinel is still struggling. ROC-AUC: 0.4935 (need â‰¥ 0.85). Accuracy: 0.4976. Keep debugging the pipeline.\n",
      "\n",
      "ğŸ“Š  Scores:\n",
      "    ROC-AUC  : 0.4935\n",
      "    Accuracy : 0.4976\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "API_URL  = \"http://localhost:8000/challenge-4\"\n",
    "CSV_FILE = \"predictions.csv\"\n",
    "\n",
    "# â”€â”€ Submit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    print(f\"âŒ '{CSV_FILE}' not found. Run Step 9 first to generate predictions.\")\n",
    "else:\n",
    "    with open(CSV_FILE, \"rb\") as f:\n",
    "        response = requests.post(API_URL, files={\"file\": (CSV_FILE, f, \"text/csv\")})\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    if result.get(\"result\") == \"success\":\n",
    "        print(\"âœ…  CHALLENGE SOLVED!\")\n",
    "        print(f\"ğŸ´  Flag     : {result['flag']}\")\n",
    "    else:\n",
    "        print(\"âŒ  Not quite right. Keep debugging!\")\n",
    "\n",
    "    print(f\"\\nğŸ’¬  {result.get('message', '')}\")\n",
    "    print(f\"\\nğŸ“Š  Scores:\")\n",
    "    print(f\"    ROC-AUC  : {result.get('roc_auc',  'N/A')}\")\n",
    "    print(f\"    Accuracy : {result.get('accuracy', 'N/A')}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f34b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
